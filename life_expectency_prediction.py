# -*- coding: utf-8 -*-
"""Life_Expectency_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W-wox9-u6bx9lLNfD6o3EBJ9er5FNP8F

**#TASK #1: UNDERSTAND THE PROBLEM STATEMENT AND BUSINESS CASE**

Life Expectancy Prediction

This data was initially obtained from WHO and United Nations Website. DAta contains features like year, status, life expectancy, adult mortality, infant deaths, percentage of expenditure, alcohol etc.

*   In this project we will train a Linear regression model to predict life expectency
*   This data was initially obtained from WHO and United Nations Website. DAta contains features like year, status, life expectancy, adult mortality, infant deaths, percentage of expenditure, alcohol etc.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""**#TASK #2: IMPORT DATASETS AND LIBRARIES**"""

life_expectancy_df = pd.read_csv('../content/drive/MyDrive/Final Year Project/Life Expectancy Prediction with Machine Learning/dataset/Life_Expectancy_Data.csv')

life_expectancy_df

life_expectancy_df.head(7)

"""**# TASK #3: PERFORM EXPLORATORY DATA ANALYSIS AND VISUALIZATION**"""

# Check the dataframe info
life_expectancy_df.info()

# check if there are any Null values
sns.heatmap(life_expectancy_df.isnull(), yticklabels = False, cbar = False, cmap="Blues")

# Statistical summary of the dataframe

life_expectancy_df.describe()

# Plot the histogram
life_expectancy_df.hist(bins = 30, figsize = (20, 20), color = 'r');

# Plot pairplot
plt.figure(figsize = (20,20))
sns.pairplot(life_expectancy_df)

"""**# Pair plot is not useful, that is why its better to use scatter plot from pair plot.**"""

sns.scatterplot(data = life_expectancy_df, x = 'Schooling', y = 'Life expectancy ')

sns.scatterplot(data = life_expectancy_df, x = 'GDP', y = 'Life expectancy ')

sns.scatterplot(data = life_expectancy_df, x = 'Income composition of resources', y = 'Life expectancy ')
plt.figure(figsize=(30, 30), dpi=80)

sns.scatterplot(data = life_expectancy_df, x = ' HIV/AIDS', y = 'Life expectancy ')

sns.scatterplot(data = life_expectancy_df, x = 'Income composition of resources', y = 'Life expectancy ')

# Plot the correlation matrix

plt.figure(figsize = (20,20))
corr_matrix = life_expectancy_df.corr()
sns.heatmap(corr_matrix, annot = True)
plt.show()

life_expectancy_df

# Checking the unique values in country to consider it as a categorical variable
life_expectancy_df['Status'].nunique()

# Perform one-hot encoding
life_expectancy_df = pd.get_dummies(life_expectancy_df, columns = ['Status'])

life_expectancy_df

# Since most of the are continous values we fill them with mean
life_expectancy_df = life_expectancy_df.apply(lambda x: x.fillna(x.mean()),axis=0)

life_expectancy_df.isnull().sum()[np.where(life_expectancy_df.isnull().sum() != 0)[0]]

"""**Find the maximum value of 'Life expectancy' in the dataframe**"""

life_expectancy_df['Life expectancy '].max()

"""**# TASK #4: CREATE TRAINING AND TESTING DATASET**

**Here in X 'Life Expectancy' is dropped as it is the target output. And the target output is intialized to y.**
"""

# Create train and test data

X = life_expectancy_df.drop(columns = ['Life expectancy '])
y = life_expectancy_df[['Life expectancy ']]

X

y

X.shape

y.shape

# Convert the data type to float32

X = np.array(X).astype('float32')
y = np.array(y).astype('float32')

# Only take the numerical variables and scale them
X

# split the data into test and train sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

#0.2=20% for testing and 0.8 rest = 80% for training the model

"""To check how much data will be trained and tested, below is code."""

X_train.shape

X_test.shape

# Scale the data
from sklearn.preprocessing import StandardScaler

scaler_X = StandardScaler()
X_train = scaler_X.fit_transform(X_train)
X_test = scaler_X.transform(X_test)

scaler_y = StandardScaler()
y_train = scaler_y.fit_transform(y_train)
y_test = scaler_y.transform(y_test)

"""**Q)Try splitting the data into 75% for training and the rest for testing**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)

"""**#TASK #5: Uderstand the theory and intuition behind linear regression.**

**Linear Regression:**


*   In simple linear regression, we predict the value of one variable Y based on another variable X.
*   X is called the independent variable, Y is called the dependant variable.
*   Why simple? Because it examines relationship between two variables only.
*   Why linear? when the independent variable increases (or decreases), the dependent variabel increases (or decreases) in a linear fashion.

**Simple Linear Regression:**
Goal is to obtain a relationship between X and y:

y=b+m*X

x=Independant Variable    
y=Dependant variable           
m=slope of line            
b= distance between the orgin and the start of the slope of line

**Multiple Linear Regression:**

*   It examines the relationship between more than two variables
*   Recall that simple linear regression is a stastical model that examines linear relationship between two variables only.
*   Each independent variable has its own corresponding coefficient.

y=b0+b1*X1+b2*X2+...+bnXn

**NOTE:**
We have used Multiple regression model because we have various diseases and causes to predict the Life Expectency

**# TASK #6: TRAIN A LINEAR REGRESSION MODEL IN SCIKIT-LEARN**
"""

# using linear regression model
from sklearn.linear_model import Grad
from sklearn.metrics import mean_squared_error, accuracy_score

regresssion_model_sklearn = LinearRegression(fit_intercept = True) #fit_intercept = True is because to get the 'b' value and if it is false then it will take 0.
regresssion_model_sklearn.fit(X_train, y_train)

regresssion_model_sklearn_accuracy = regresssion_model_sklearn.score(X_test, y_test)
regresssion_model_sklearn_accuracy

print('Linear Model Coefficient (m): ', regresssion_model_sklearn.coef_)
print('Linear Model Coefficient (b): ', regresssion_model_sklearn.intercept_)

"""**Q) Retrain the model while setting the fit_intercept = False, what do you notice?**"""

#regresssion_model_sklearn = LinearRegression(fit_intercept = False)
#regresssion_model_sklearn.fit(X_train, y_train)

#print('Linear Model Coefficient (m): ', regresssion_model_sklearn.coef_)
#print('Linear Model Coefficient (b): ', regresssion_model_sklearn.intercept_)

"""**TASK #7: EVALUATE TRAINED MODEL PERFORMANCE**"""

# Make prediction

y_predict = regresssion_model_sklearn.predict(X_test)

y_predict

# Plot the scaled result

plt.plot(y_test, y_predict, "^", color = 'r')
plt.xlabel('Model Predictions')
plt.ylabel('True Values')

"""**Here we go with the orginal values using 'inverse_transform'.**"""

y_predict_orig = scaler_y.inverse_transform(y_predict)
y_test_orig = scaler_y.inverse_transform(y_test)

# Plot the original values

plt.plot(y_test_orig, y_predict_orig, "^", color = 'r')
plt.xlabel('Model Predictions')
plt.ylabel('True Values')

# Plot the KPIs--> Which will help in finding Root Mean Square error, Mean square error, Mean Absolute error, r2.

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from math import sqrt

k = X_test.shape[1]
n = len(X_test)
RMSE = float(format(np.sqrt(mean_squared_error(y_test_orig, y_predict_orig)),'.3f'))
MSE = mean_squared_error(y_test_orig, y_predict_orig)
MAE = mean_absolute_error(y_test_orig, y_predict_orig)
r2 = r2_score(y_test_orig, y_predict_orig)
adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)

print('RMSE =',RMSE, '\nMSE =',MSE, '\nMAE =',MAE, '\nR2 =', r2, '\nAdjusted R2 =', adj_r2)

"""**Q) Retrain the model and list the KPIs with fit_intercept = False. What do you notice? why?**"""

plt.plot(y_test_orig, y_predict_orig, "^", color = 'b')
plt.xlabel('Model Predictions')
plt.ylabel('True Values')

